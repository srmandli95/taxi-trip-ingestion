# Example Airflow environment variables
# Copy this file to `airflow/.env` and fill in real values locally.
# Do NOT commit `airflow/.env` — it's already ignored via .gitignore.

# GCP project & region
AIRFLOW_VAR_GCP_PROJECT="nyc-analytics-dev-477913"
AIRFLOW_VAR_GCP_REGION="us-central1"

# GCS data bucket
AIRFLOW_VAR_DATA_BUCKET="nyc-analytics-dev-data"

# Service account email (used by Dataproc runtimes, etc.)
AIRFLOW_VAR_DATAPROC_RUNTIME_SA="dataproc-runtime@nyc-analytics-dev-477913.iam.gserviceaccount.com"

# External API keys (replace with your secret; keep in airflow/.env only)
AIRFLOW_VAR_WEATHER_API_KEY="REPLACE_WITH_WEATHER_API_KEY"

# GCP credentials: point to a downloaded service account JSON key
# Download from GCP Console: Service Accounts → [your-sa] → Keys → Create Key (JSON)
# Save to ~/.gcp/service-account-key.json and update the path below
GOOGLE_APPLICATION_CREDENTIALS="$HOME/.gcp/service-account-key.json"

# Airflow GCP Connection setup (for Airflow webserver / astro dev)
# After downloading the service account key, create an Airflow Connection named 'google_cloud_default':
#   1. In Airflow UI: Admin → Connections → Create
#   2. Connection ID: google_cloud_default
#   3. Connection Type: Google Cloud
#   4. Keyfile JSON: [paste the entire contents of your service-account-key.json]
#   5. Project ID: nyc-analytics-dev-477913
# Or use Airflow CLI:
#   astro run airflow connections add google_cloud_default --conn-type google_cloud --conn-extra '{"type":"service_account",...}'

# Quick setup for local development:
# 1. cp airflow/.env.example airflow/.env
# 2. Download your GCP service account key JSON to ~/.gcp/service-account-key.json
# 3. Edit airflow/.env to ensure GOOGLE_APPLICATION_CREDENTIALS path is correct
# 4. In your zsh session:
#    set -a
#    source airflow/.env
#    set +a
# 5. Start Astronomer:
#    astro dev restart
# 6. In Airflow UI, create the 'google_cloud_default' connection with your service account JSON
